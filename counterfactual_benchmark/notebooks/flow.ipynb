{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "0d143269",
   "metadata": {},
   "source": [
    "# Counterfactual Benchmark Notebook\n",
    "- This notebook compacts what this repository does by showing an example for a GAN for Celeba Simple dataset\n",
    "- This notebook must be execute in-place inside the repo\n",
    "- Clone the repo and get a conda env with the correct packages"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "21f689e5",
   "metadata": {},
   "source": [
    "# Part 1: Training\n",
    "- Start by "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "700455f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "#imports from root to use local packages\n",
    "import os, sys\n",
    "sys.path.append(os.path.abspath(os.path.join(os.getcwd(), '..')))\n",
    "\n",
    "from models.gans.celeba_gan import CelebaCondGAN\n",
    "from datasets.celeba.dataset import Celeba\n",
    "from models.classifiers.celeba_classifier import CelebaClassifier\n",
    "import torch\n",
    "import joblib\n",
    "from pytorch_lightning import Trainer\n",
    "from torchvision.transforms import RandomHorizontalFlip\n",
    "from datasets.transforms import SelectParentAttributesTransform\n",
    "from models.utils import generate_checkpoint_callback, generate_early_stopping_callback, generate_ema_callback"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bdc6bf64",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_dataloaders(data_class, attribute_size, config, transform=None, **kwargs):\n",
    "    data = data_class(attribute_size=attribute_size, transform=transform, split='train', **kwargs)\n",
    "\n",
    "    if data.has_valid_set:\n",
    "        train_set = data\n",
    "        val_set = data_class(attribute_size=attribute_size, transform=transform, split='valid', **kwargs)\n",
    "    else:\n",
    "        train_set, val_set = torch.utils.data.random_split(data, [config[\"train_val_split\"], 1 - config[\"train_val_split\"]])\n",
    "\n",
    "    train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=config[\"batch_size_train\"], shuffle=True, num_workers=7)\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_set, batch_size=config[\"batch_size_val\"], shuffle=False, num_workers=7)\n",
    "    return train_data_loader, val_data_loader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1099e64b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_gan(gan, config, data_class, graph_structure, attribute_size, checkpoint_dir, **kwargs):\n",
    "    transform = SelectParentAttributesTransform(\"image\", attribute_size, graph_structure)\n",
    "\n",
    "    train_data_loader, val_data_loader = get_dataloaders(data_class, attribute_size, config, transform, **kwargs)\n",
    "\n",
    "    monitor= \"fid\" if config['finetune'] == 0 else \"lpips\"\n",
    "    callbacks = [\n",
    "        generate_checkpoint_callback(gan.name, checkpoint_dir, monitor=monitor),\n",
    "        generate_early_stopping_callback(patience=config[\"patience\"], monitor=monitor)\n",
    "    ]\n",
    "\n",
    "\n",
    "    trainer = Trainer(accelerator=\"auto\", devices=\"auto\", strategy=\"auto\",\n",
    "                      callbacks=callbacks,\n",
    "                      default_root_dir=checkpoint_dir, max_epochs=config[\"max_epochs\"])\n",
    "\n",
    "    trainer.fit(gan, train_data_loader, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e352d2e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# define causal graph (canibalised from config/../gan.json)\n",
    "causal_graph = {\n",
    "        \"Smiling\": [],\n",
    "        \"Eyeglasses\": [],\n",
    "        \"image\": [\"Smiling\", \"Eyeglasses\"]\n",
    "    },\n",
    "\n",
    "#define the models for each mechanism (only one for image here as the rest in the graph are roots)\n",
    "mechanism_models =  {\n",
    "        \"image\": {\n",
    "            \"model_type\": \"gan\",\n",
    "            \"model_class\": \"CelebaCondGAN\",\n",
    "            \"module\": \"models.gans\",\n",
    "            \"params\": {\n",
    "                \"n_chan_enc\": [3, 64, 128, 256, 256, 512, 512],\n",
    "                \"n_chan_gen\": [512 ,512, 256, 256, 128, 64, 3],\n",
    "                \"latent_dim\": 512,\n",
    "                \"num_continuous\": 2,\n",
    "                \"d_updates_per_g_update\": 1,\n",
    "                \"gradient_clip_val\": 0.5,\n",
    "                \"finetune\": 1,\n",
    "                \"pretrained_path\": \"\",\n",
    "                \"lr\": 1e-4,\n",
    "                \"batch_size_train\": 128,\n",
    "                \"batch_size_val\": 128,\n",
    "                \"patience\": 10,\n",
    "                \"max_epochs\": 1000\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "\n",
    "attribute_size = {\n",
    "        \"Smiling\": 1,\n",
    "        \"Eyeglasses\": 1\n",
    "         },"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5100fee9",
   "metadata": {},
   "source": [
    "### Train model:\n",
    "- Train the GAN model for Celeb data set image generation:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c8eff89f",
   "metadata": {},
   "outputs": [],
   "source": [
    "for variable in causal_graph:\n",
    "    if variable not in mechanism_models: continue #only want to train variables with models, root variables don't have a causal mechanism\n",
    "    train_gan(\n",
    "        gan=CelebaCondGAN,\n",
    "        config=mechanism_models[variable][\"params\"],\n",
    "        data_class=Celeba,\n",
    "        graph_structure=causal_graph,\n",
    "        attribute_size=attribute_size,\n",
    "        checkpoint_dir=\"../methods/deepscm/checkpoints/celeba/simple/trained_scm\" #adjusted default path because the notebook is down one\n",
    "        )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c0618f0f",
   "metadata": {},
   "source": [
    "### Train Classifier:\n",
    "- Train the classifiers for each attribute which will be used later for evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a3f45504",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_classifier(classifier, attr, train_set, val_set, config, default_root_dir, weights=None):\n",
    "    mode = 'min' if attr in [\"age\", \"brain_vol\", \"vent_vol\", \"thickness\", \"intensity\"] else 'max'\n",
    "\n",
    "    callbacks = [\n",
    "        generate_checkpoint_callback(attr + \"_classifier\", config[\"ckpt_path\"], monitor=\"val_metric\", mode=mode),\n",
    "        generate_early_stopping_callback(patience=config[\"patience\"], monitor=\"val_metric\", mode=mode, min_delta=1e-5)\n",
    "    ]\n",
    "\n",
    "    if config[\"ema\"] == \"True\":\n",
    "        callbacks.append(generate_ema_callback(decay=0.999))\n",
    "\n",
    "    trainer = Trainer(accelerator=\"auto\", devices=\"auto\", strategy=\"auto\",\n",
    "                      callbacks=callbacks,\n",
    "                      default_root_dir=default_root_dir, max_epochs=config[\"max_epochs\"])\n",
    "\n",
    "    if weights != None:\n",
    "        sampler = torch.utils.data.sampler.WeightedRandomSampler(weights, len(train_set), replacement=True)\n",
    "        print(\"Using sampler!\")\n",
    "        train_data_loader = torch.utils.data.DataLoader(train_set, sampler=sampler, batch_size=config[\"batch_size_train\"],  drop_last=False, num_workers=7)\n",
    "    else:\n",
    "        train_data_loader = torch.utils.data.DataLoader(train_set, batch_size=config[\"batch_size_train\"], shuffle=True, drop_last=False, num_workers=7)\n",
    "\n",
    "\n",
    "    val_data_loader = torch.utils.data.DataLoader(val_set, batch_size=config[\"batch_size_val\"], shuffle=False, num_workers=7)\n",
    "    trainer.fit(classifier, train_data_loader, val_data_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c18702da",
   "metadata": {},
   "outputs": [],
   "source": [
    "config_cls = {\n",
    "    \"attribute_size\": {\n",
    "        \"Smiling\": 1,\n",
    "        \"Eyeglasses\": 1\n",
    "    },\n",
    "\n",
    "    \"dataset\": \"celeba\",\n",
    "    \"ckpt_path\" : \"../methods/deepscm/checkpoints/celeba/simple/trained_classifiers\", #modified this line for the notebook\n",
    "    \"in_shape\" : [3, 64, 64] ,\n",
    "    \"patience\" : 10,\n",
    "    \"batch_size_train\" : 128,\n",
    "    \"batch_size_val\" : 128,\n",
    "    \"lr\" : 1e-3,\n",
    "    \"max_epochs\" : 1000,\n",
    "    \"ema\": \"True\"\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "39f834b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "for attribute in attribute_size.keys():\n",
    "\n",
    "    classifier = CelebaClassifier(attr=attribute, num_outputs=attribute_size[attribute], lr=config_cls[\"lr\"])\n",
    "\n",
    "    train_set = Celeba(attribute_size=attribute_size, split=\"train\", transform_cls=RandomHorizontalFlip(0.5))\n",
    "\n",
    "    #weights:\n",
    "    if attribute == \"Smiling\":\n",
    "        weights = torch.tensor(joblib.load(\"../../datasets/celeba/weights/weights_smiling.pkl\")).double() #this path may need updating\n",
    "\n",
    "    elif attribute == \"Eyeglasses\":\n",
    "        weights = torch.tensor(joblib.load(\"../../datasets/celeba/weights/weights_eyes.pkl\")).double()\n",
    "\n",
    "    elif attribute in {\"No_Beard\", \"Bald\"}:\n",
    "        labels = train_set.attrs[: , classifier.variables[attribute]].long()\n",
    "        print((labels == 1).sum(), (labels==0).sum())\n",
    "        class_count = torch.tensor([(labels == t).sum() for t in torch.unique(labels, sorted=True)])\n",
    "        print(class_count)\n",
    "        class_weights = 1. / class_count.float()\n",
    "\n",
    "        weights = class_weights[labels]\n",
    "        print(weights)\n",
    "\n",
    "    else:\n",
    "        weights = None\n",
    "\n",
    "    train_classifier(\n",
    "        classifier=classifier,\n",
    "        attr=attribute,\n",
    "        train_set=train_set,\n",
    "        config=config_cls,\n",
    "        default_root_dir=config_cls[\"ckpt_path\"],\n",
    "        weights=weights\n",
    "    )"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e92455e0",
   "metadata": {},
   "source": [
    "# Part 2: Evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "99053ee0",
   "metadata": {},
   "source": [
    "We will start by running the model (abduction, action, and prediction), then comparing its output to the classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "15c0afba",
   "metadata": {},
   "outputs": [],
   "source": [
    "def produce_counterfactuals(factual_batch: torch.Tensor, scm: nn.Module, do_parent:str, intervention_source: Dataset,\n",
    "                            force_change: bool = False, possible_values = None, device: str = 'cuda', bins = None):\n",
    "    factual_batch = {k: v.to(device) for k, v in factual_batch.items()}\n",
    "\n",
    "    #update with the counterfactual parent\n",
    "    if force_change:\n",
    "        possible_values = possible_values[do_parent]\n",
    "        values = factual_batch[do_parent].cpu()\n",
    "        if do_parent not in [\"digit\", \"apoE\", \"slice\"]:\n",
    "            interventions = {do_parent: torch.cat([torch.tensor(np.random.choice(possible_values[different_value(possible_values, value, bins, do_parent)])).unsqueeze(0)\n",
    "                                                for value in values]).view(-1).unsqueeze(1).to(device)}\n",
    "        else:\n",
    "            interventions = {do_parent: torch.cat([torch.tensor(rng.choice(possible_values[torch.where((different_value(possible_values, value, bins, do_parent)).any(dim=1))], axis=0)).unsqueeze(0)\n",
    "                                                for value in values]).to(device)}\n",
    "    else:\n",
    "        batch_size, _ , _ , _ = factual_batch[\"image\"].shape\n",
    "        idxs = torch.randperm(len(intervention_source))[:batch_size] # select random indices from train set to perform interventions\n",
    "\n",
    "        interventions = {do_parent: torch.cat([intervention_source[id][do_parent] for id in idxs]).view(-1).unsqueeze(1).to(device)\n",
    "                        if do_parent not in [\"digit\", \"apoE\", \"slice\"] else torch.cat([intervention_source[id][do_parent].unsqueeze(0).to(device) for id in idxs])}\n",
    "\n",
    "    abducted_noise = scm.encode(**factual_batch)\n",
    "    counterfactual_batch = scm.decode(interventions, **abducted_noise)\n",
    "\n",
    "    return counterfactual_batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0d433ed",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def evaluate_effectiveness(test_set: Dataset, unnormalize_fn, batch_size:int , scm: nn.Module, attributes: List[str], do_parent:str,\n",
    "                           intervention_source: Dataset, predictors: Dict[str, Classifier], dataset: str):\n",
    "\n",
    "    test_data_loader = torch.utils.data.DataLoader(test_set, batch_size=batch_size, shuffle=False, num_workers=7)\n",
    "\n",
    "    effectiveness_scores = {attr_key: [] for attr_key in attributes}\n",
    "    for factual_batch in tqdm(test_data_loader):\n",
    "        counterfactuals = produce_counterfactuals(factual_batch, scm, do_parent, intervention_source,\n",
    "                                                  force_change=True, possible_values=test_set.possible_values, bins=test_set.bins)\n",
    "        e_score = effectiveness(counterfactuals, unnormalize_fn, predictors, dataset)\n",
    "\n",
    "        for attr in attributes:\n",
    "            effectiveness_scores[attr].append(e_score[attr])\n",
    "\n",
    "    effectiveness_score = {key  : (round(np.mean(score), 3), round(np.std(score), 3)) for key, score in effectiveness_scores.items()}\n",
    "\n",
    "    print(f\"Effectiveness score do({do_parent}): {effectiveness_score}\")\n",
    "\n",
    "    return effectiveness_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab683c59",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "counterfactual-benchmarks",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
